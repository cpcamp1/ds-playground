{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week9 Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In week 9, we've covered:\n",
    "\n",
    "* **Clustering**\n",
    "\n",
    "In this notebook, we will work on an Online Retail dataset to explore customer segmentation through the unsupervised learning method, and apply association rule mining approach to find interesting rules and patterns in this transaction database. \n",
    "\n",
    "The dataset for this project contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail. The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers. This dataset contains following information:\n",
    "\n",
    "* InvoiceNo: A unique identifier for the invoice. An invoice number shared across rows means that those transactions * were performed in a single invoice (multiple purchases).\n",
    "* StockCode: Identifier for items contained in an invoice.\n",
    "* Description: Textual description of each of the stock item.\n",
    "* Quantity: The quantity of the item purchased.\n",
    "* InvoiceDate: Date of purchase.\n",
    "* UnitPrice: Value of each item.\n",
    "* CustomerID: Identifier for customer making the purchase.\n",
    "* Country: Country of customer.\n",
    "\n",
    "Instructions will be provided for each section and the specifics of the implementation are marked in the code block with a TODO statement.\n",
    "\n",
    "[Google](www.google.com), [Python Documentation](https://docs.python.org/3/contents.html), and [scikit-learn Documentation](https://scikit-learn.org/stable/) are your good friends if you have any python questions.\n",
    "\n",
    "Download **Week9_Unsupervised_Learning_Homework.ipynb** notebook to your local folder and open it with Jupyter Notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Python SciPy libraries (ex. `numpy`, `pandas`, `matplotlib`, `seaborn`)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print dimensions of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print statistical summary of all numerical attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check for missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Disregard any records without customer id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove all records in that quantity or unit price is negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add a column to show the total sales amount for each line of transaction record\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show top 10 customers based on the total sales amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use bar plot to show top 10 products based on the total sales amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use bar plot to show when (which month) we generate most revenue in a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Towards the end of the year, sales make a huge jump to over a million."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have created our customer transaction dataset, we will perform some preprocessing on the data. \n",
    "\n",
    "In this practice, we would like to leverage RFM analysis to explore customer segmentation. RFM analysis depends\n",
    "on Recency (R), Frequency (F), and Monetary (M) measures which are three important\n",
    "purchase-related variables that influence the future purchase possibilities of the customers. \n",
    "\n",
    "* R -- How long has it been since the customerâ€™s last purchase?\n",
    "* F -- How often has the customer made a purchase over a defined period of time?\n",
    "* M -- How much money has the customer spend with us over a defined period of time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataset is named as df\n",
    "# --Group data by customerID--\n",
    "# Create snapshot date\n",
    "snapshot_date = df['InvoiceDate'].max() + timedelta(days=1)\n",
    "print(snapshot_date)\n",
    "# Grouping by CustomerID\n",
    "df_process = df.groupby(['CustomerID']).agg({\n",
    "    'InvoiceDate': lambda x: (snapshot_date - x.max()).days,\n",
    "    'InvoiceNo': 'count',\n",
    "    'TotalAmount': 'sum'})\n",
    "# Rename the columns \n",
    "df_process.rename(columns={'InvoiceDate': 'Recency',\n",
    "                           'InvoiceNo': 'Frequency',\n",
    "                           'TotalAmount': 'Monetary'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our clustering, we will be using the K-means clustering algorithm. One of the requirements for proper functioning of the algorithm is the mean centering of the variable values. Mean centering of a variable value means that we will replace the actual value of the variable with a standardized value, so that the variable has a mean of 0 and variance of 1. This ensures that all the variables are in the same range and the difference in ranges of values doesn't cause the algorithm to not perform well. This is akin to feature scaling.\n",
    "\n",
    "Another problem that you can investigate about is the huge range of values each variable can take. This problem is particularly noticeable for the monetary amount variable. To take care of this problem, we will transform all the variables on the log scale. This transformation, along with the standardization, will ensure that the input to our algorithm is a homogenous set of scaled and transformed values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply log transformation and StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering\n",
    "\n",
    "Recall that in K-Means Clustering we want to *maximize* the distance between centroids and *minimize* the distance between data points and the respective centroid for the cluster they are in. True evaluation for unsupervised learning would require labeled data; however, we can use a variety of intuitive metrics to try to pick the number of clusters K. We will introduce two methods: the Elbow method and the Silhouette method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing K: The Elbow Sum-of-Squares Method\n",
    "\n",
    "The first method looks at the sum-of-squares error in each cluster against $K$. We compute the distance from each data point to the center of the cluster (centroid) to which the data point was assigned. \n",
    "\n",
    "$$SS = \\sum_k \\sum_{x_i \\in C_k} \\sum_{x_j \\in C_k} \\left( x_i - x_j \\right)^2 = \\sum_k \\sum_{x_i \\in C_k} \\left( x_i - \\mu_k \\right)^2$$\n",
    "\n",
    "where $x_i$ is a point, $C_k$ represents cluster $k$ and $\\mu_k$ is the centroid for cluster $k$. We can plot SS vs. $K$ and choose the *elbow point* in the plot as the best value for $K$. The elbow point is the point at which the plot starts descending much more slowly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing K: The Silhouette Method\n",
    "\n",
    "There exists another method that measures how well each datapoint $x_i$ \"fits\" its assigned cluster *and also* how poorly it fits into other clusters. This is a different way of looking at the same objective. Denote $a_{x_i}$ as the *average* distance from $x_i$ to all other points within its own cluster $k$. The lower the value, the better. On the other hand $b_{x_i}$ is the minimum average distance from $x_i$ to points in a different cluster, minimized over clusters. That is, compute separately for each cluster the average distance from $x_i$ to the points within that cluster, and then take the minimum. The silhouette $s(x_i)$ is defined as\n",
    "\n",
    "$$s(x_i) = \\frac{b_{x_i} - a_{x_i}}{\\max{\\left( a_{x_i}, b_{x_i}\\right)}}$$\n",
    "\n",
    "The silhouette score is computed on *every datapoint in every cluster*. The silhouette score ranges from -1 (a poor clustering) to +1 (a very dense clustering) with 0 denoting the situation where clusters overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional\n",
    "#### Visualization of Clusters using PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span12 alert alert-info\">\n",
    "<li> Use scikit-learn's [`PCA`](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) function to reduce the dimensionality of your clustering data to 2 components (label them x and y)\n",
    "<li> Choose a value of K from above and use KMeans to cluster using the two PCA components (x and y)\n",
    "<li> Create a data frame with the following fields:\n",
    "  <ul>\n",
    "  <li> customer id\n",
    "  <li> cluster id \n",
    "  <li> PCA component x\n",
    "  <li> PCA component y    \n",
    "  </ul>\n",
    "<li> Plot a scatterplot of the x vs y columns and color-code points differently based on cluster ID\n",
    "<li> How do the clusters look? \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Commit your completed **Week9_Unsupervised_Learning_Homework.ipynb** notebook to your personal Github repo you shared with the faculty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
